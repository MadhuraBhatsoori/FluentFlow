<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>FluentFlow</title>
    <script src="/socket.io/socket.io.js"></script>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: #f5f5f5;
        }
        .container {
            background: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            text-align: center;
        }
        .controls {
            margin: 20px 0;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 8px;
            display: flex;
            gap: 10px;
            justify-content: center;
        }
        .image {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .image img {
            width: 400px;
            height: 400px;
            margin: 0 auto;
        }
        button {
            padding: 10px 20px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-weight: 500;
            transition: background-color 0.2s;
        }
        .start-btn {
            background: #2ecc71;
            color: white;
        }
        .stop-btn {
            background: #e74c3c;
            color: white;
        }
        .report-btn{
            background: rgb(200, 193, 193);
            cursor: not-allowed;
        }
        h1 {
            text-align: center;
            margin-top: 50px;
        }
        .status-text {
            margin-top: 10px;
            font-style: italic;
            color: #666;
        }
        .error-text {
            color: #e74c3c;
            margin-top: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>FluentFlow</h1>
        <div class="image">
            <img src="green.png" alt="Audio Processing Illustration" id="statusImage">
        </div>
        <div class="controls">
            <button class="start-btn" id="startButton" onclick="startProcessing()">Start Recording</button>
            <button class="stop-btn" id="stopButton" onclick="stopProcessing()" disabled>Stop Recording</button>
            
        </div>
        <div class="report">
            <button class="report-btn" id="getReportButton" onclick="getAnalysisReport()">Get Analysis Report</button>
        </div>

    </div>

    <script>
        const socket = io();
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;

        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const statusText = document.getElementById('statusText');
        const errorText = document.getElementById('errorText');

        function updateStatus(message, isError = false) {
            if (isError) {
                errorText.textContent = message;
                statusText.textContent = '';
            } else {
                statusText.textContent = message;
                errorText.textContent = '';
            }
            console.log(isError ? 'Error: ' : 'Status: ', message);
        }

        async function startProcessing() {
            try {
                startButton.disabled = true;
                stopButton.disabled = false;
                audioChunks = [];
                isRecording = true;

                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        channelCount: 1,
                        sampleRate: 44100,
                        sampleSize: 16
                    } 
                });

                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm;codecs=opus'
                });

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };

                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
    
    
                    const reader = new FileReader();
                    reader.onload = () => {
                        const base64Audio = reader.result;  
                           socket.emit('audioData', {
                                audio: base64Audio,
                                timestamp: Date.now(),
                                format: 'wav'
                            });
                    updateStatus('Processing audio...');
    };
    reader.readAsDataURL(audioBlob);
};
                mediaRecorder.start(1000); 
                socket.emit('startProcessing');
                updateStatus('Recording started');

            } catch (error) {
                updateStatus(`Microphone access error: ${error.message}`, true);
                resetButtons();
            }
        }

        function stopProcessing() {
    if (mediaRecorder && mediaRecorder.state === 'recording') {
        isRecording = false;
        mediaRecorder.stop();
        mediaRecorder.stream.getTracks().forEach(track => track.stop());
        socket.emit('stopProcessing');
        updateStatus('Recording stopped');
        resetButtons();
        showReportButton();   
    }
}

        function resetButtons() {
            startButton.disabled = false;
            stopButton.disabled = true;
        }

        function getAnalysisReport() {
            window.location.href = 'analysis.html';
   
        }

        function updateImage(status) {
            const image = document.getElementById('statusImage');
            image.src = status === 'match' ? 'red.png' : 'green.png';
        }

        socket.on('connect', () => {
            updateStatus('Connected to server');
            resetButtons();
        });

        socket.on('connect_error', (error) => {
            updateStatus(`Connection error: ${error.message}`, true);
            resetButtons();
        });

        socket.on('audioMatch', (match) => {
            updateImage('match');
            setTimeout(() => updateImage('default'), 3000);
        });

        socket.on('processingStatus', (data) => {
            updateStatus(data.message, data.status === 'error');
        });

        socket.on('recordingSaved', (response) => {
            updateStatus(response.message || 'Recording saved successfully');
        });

        socket.on('error', (error) => {
            updateStatus(error.message || 'An error occurred', true);
            resetButtons();
        });

        window.addEventListener('beforeunload', () => {
            if (isRecording) {
                stopProcessing();
            }
        });
    </script>
</body>
</html>